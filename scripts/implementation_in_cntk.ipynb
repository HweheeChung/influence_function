{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HVP\n",
    "\n",
    "implement HVP using cntk\n",
    "refer: https://cntk.ai/pythondocs/cntk.ops.functions.html#cntk.ops.functions.Function.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from cntk.device import try_set_default_device, gpu\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate HVP using $\\frac{g(x+rv)-g(x-rv)}{2r}$.\n",
    "\n",
    "더 정확하게는\n",
    "\n",
    "$\\frac{g_{w+rv}(x)-g_{w-rv}(x)}{2r}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_update(w, v, r):\n",
    "    # w: weights of neural network (tuple)\n",
    "    # v: value for delta w (dictionary, e.g., gradient value)\n",
    "    # r: hyperparameter for a gradient (scalar)\n",
    "\n",
    "    for p in w:\n",
    "        p.value += r * v[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HVP(y, x, v):\n",
    "    # Calculate Hessian vector product \n",
    "    # y: scalar function to be differentiated (function, e.g. cross entropy loss)\n",
    "    # x: feed_dict value for the network (dictionary, e.g. {model.X: image_batch, model.y: label_batch})\n",
    "    # v: vector to be producted (by Hessian) (numeric dictionary, e.g., g(z_test))\n",
    "    ## w: variables to differentiate (numeric, e.g. neural network weight)\n",
    "    \n",
    "    # hyperparameter r\n",
    "    r = 1e-2\n",
    "    \n",
    "    assert type(x)==dict, \"Input of HVP is wrong. this should be dictionary\"\n",
    "     \n",
    "    w = y.parameters\n",
    "    \n",
    "    # gradient for plus\n",
    "    weight_update(w, v, +r)\n",
    "    g_plus = y.grad(x, wrt=params)\n",
    "  \n",
    "    # gradient for minus\n",
    "    weight_update(w, v, -2*r)\n",
    "    g_minus = y.grad(x, wrt=params)\n",
    "    \n",
    "    # weight reconstruction\n",
    "    weight_update(w, v, +r)\n",
    "    \n",
    "    hvp = {ks: (g_plus[ks] - g_minus[ks])/(2*r) for ks in g_plus.keys()}\n",
    "       \n",
    "    return hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_inner_product(grad1, grad2):\n",
    "    # inner product for dictionary-format gradients (output scalar value)\n",
    "    \n",
    "    val = 0\n",
    "    \n",
    "    for ks in grad1.keys():\n",
    "        #C.inner(grad1[ks], grad2[ks])\n",
    "        val += np.sum(np.multiply(grad1[ks],grad2[ks]))\n",
    "        #val += np.dot(grad1[ks], grad2[ks])\n",
    "        \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Parameter('W', [], [1 x 1]): array([[ 0.99999905]], dtype=float32),\n",
       " Parameter('W', [], [1 x 1]): array([[ 0.99999905]], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example for HVP\n",
    "\n",
    "x = C.input_variable(shape=(1,))\n",
    "h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(x)\n",
    "y = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(h)\n",
    "\n",
    "params = y.parameters\n",
    "x_feed = {x:[[1.]]}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "HVP(y, x_feed, v_feed)\n",
    "\n",
    "# output should be 1, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 답은 1.0, 1.0이 나와야 함. 이런 차이는 hyperparameter r과 관계가 있을 것. r이 작이질 수록 오차도 적어질 것으로 예상되지만, 지나치게 r이 적게 되면 precision number보다 적은 값이 나와서 문제가 생길 수 있음. 특히 gradient 값이 작은 부분에선 큰 문제가 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST DATASET & NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../refer/boot_strapping')\n",
    "import json\n",
    "\n",
    "from datasets import dataset28 as dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image_from_data(img):\n",
    "    # show image from dataset\n",
    "    # img: (C,W,H) numpy array\n",
    "    img_show = np.squeeze(np.transpose(img, [1,2,0]))\n",
    "    imshow(img_show)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 <class 'datasets.dataset28.LazyDataset'>\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# emnist dataset\n",
    "root_dir = '/Data/emnist/balanced/original'\n",
    "\n",
    "# sample sized\n",
    "trainval_list, anno_dict = dataset.read_data_subset(root_dir, mode='train1', sample_size=1000)\n",
    "test_list, _ = dataset.read_data_subset(root_dir, mode='validation1', sample_size=1000)\n",
    "\n",
    "with open('/Data/emnist/balanced/original/annotation/annotation1_wp_0.3.json','r') as fid:\n",
    "    noisy_anno_dict = json.load(fid)\n",
    "\n",
    "train_set = dataset.LazyDataset(root_dir, trainval_list, noisy_anno_dict)\n",
    "test_set = dataset.LazyDataset(root_dir, test_list, anno_dict)\n",
    "\n",
    "# emnist dataset: SANITY CHECK\n",
    "print(len(test_set), type(test_set))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.shape (64, 28, 28)\n",
      "pool1.shape (64, 14, 14)\n",
      "conv2.shape (128, 14, 14)\n",
      "pool2.shape (128, 7, 7)\n",
      "conv3.shape (256, 7, 7)\n",
      "pool3.shape (256, 4, 4)\n",
      "Test error rate: 0.1052667025862069\n",
      "Total tack time(sec): 3.5198941230773926\n",
      "Tact time per image(sec): 0.0035198941230773924\n",
      "Confusion matrix: \n",
      "[[17  0  0 ...,  0  0  0]\n",
      " [ 0  7  0 ...,  0  0  0]\n",
      " [ 0  0 21 ...,  0  0  0]\n",
      " ..., \n",
      " [ 0  0  0 ..., 14  0  0]\n",
      " [ 0  0  0 ...,  0 23  0]\n",
      " [ 0  0  0 ...,  0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "# emnist network\n",
    "from models.nn import VGG as ConvNet\n",
    "\n",
    "hp_d = dict() # hyperparameters for a network\n",
    "model = ConvNet(train_set.__getitem__(0)[0].shape, len(anno_dict['classes']), **hp_d)\n",
    "model.logits.restore('/Data/checkpts/noisy/model_fold_1_trainval_ratio_1.0.dnn')\n",
    "\n",
    "# emnist network: SANITY CHECK\n",
    "start_time = time.time()\n",
    "ys, y_preds, test_score, confusion_matrix = model.predict(test_set, **hp_d)\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print('Test error rate: {}'.format(test_score))\n",
    "print('Total tack time(sec): {}'.format(total_time))\n",
    "print('Tact time per image(sec): {}'.format(total_time / len(test_list)))\n",
    "print('Confusion matrix: \\n{}'.format(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stochastic estimation\n",
    "def IHVP(model, y, v, data_set): # data, network, etc. as we did in GradCAM\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    \n",
    "    # hyperparameters (hp_d)\n",
    "    recursion_depth = 50\n",
    "    scale = 1e3\n",
    "    damping = 1.0 # paper ref:0.01\n",
    "    batch_size = 50\n",
    "    num_samples = 1 # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "                #break\n",
    "            print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "        \n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    return inv_hvps\n",
    "    \n",
    "    # average among samples\n",
    "    #ihvp = average(inv_hvps)\n",
    "    #return ihvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth label:  I\n",
      "network prediction:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAEJpJREFUeJzt3XuMXOV5x/Hfs+u92GtjjC9gjMGG\n2tTgctMWE9FSJ8guUFIbpVCoRF0V4UgJbSNREYTaQKMi0ahJStIW1TROTLmngeAoqIW6TQlp5Hgh\nXOyYm4gxvuALxtjGwd7defrHjqMN7HnOMLcz6/f7kdDOzjPvzMPx/vbM7HvOec3dBSA9bUU3AKAY\nhB9IFOEHEkX4gUQRfiBRhB9IFOEHEkX4gUQRfiBRY5r5Yp3W5d3qaeZLAkl5X+/psB+ySh5bU/jN\n7BJJd0pql/Sv7n5H9Phu9WiBXVzLSwIIrPU1FT+26rf9ZtYu6Z8kXSrpDEnXmNkZ1T4fgOaq5TP/\n+ZJec/fX3f2wpAclLalPWwAarZbwz5D05rDvt5Tv+xVmttzM+sysr1+Hang5APVUS/hH+qPCh84P\ndvcV7t7r7r0d6qrh5QDUUy3h3yJp5rDvT5K0rbZ2ADRLLeFfJ2mOmc02s05JV0taXZ+2ADRa1VN9\n7j5gZjdI+k8NTfWtdPcNdesMQEPVNM/v7o9LerxOvQBoIg7vBRJF+IFEEX4gUYQfSBThBxJF+IFE\nNfV8/qNVW3d3XJ86JX6CjvifYXDi6L0GQtv+g5k1744P9/aO9ppeu33X3szawNacg1ETWMmKPT+Q\nKMIPJIrwA4ki/ECiCD+QKMIPJIqpvgq1jRuXWdux7OxwbOcnd4X1aT0Hwvonp64L6x02GNYbqd/j\n6bgndmdf0/U3Jr4Sjj258+2aXvvODZ/IrM36mwnh2NL6l8L60YA9P5Aowg8kivADiSL8QKIIP5Ao\nwg8kivADiWKev0I2e2ZmbdHyH4djb536k7DeYfF8dduIiyONDtdN3JxZa/T/12UL7sqsLb7ypnDs\nrJc7w7r3H66qp1bCnh9IFOEHEkX4gUQRfiBRhB9IFOEHEkX4gUTVNM9vZpsk7Zc0KGnA3Xvr0VQr\nKnVmb6q53W+FY7ustsMpBhSfr9/vxZ3Pn2d/aSCz9sP3Z9T03CeP2RPWTwk2+0BPqabXPhrU4yCf\nj7v77jo8D4Am4m0/kKhaw++SnjCzZ8xseT0aAtActb7tv9Ddt5nZNElPmtlL7v7U8AeUfyksl6Ru\nZV8HD0Bz1bTnd/dt5a87JT0q6fwRHrPC3XvdvbdD8dpsAJqn6vCbWY+ZTThyW9JiSevr1RiAxqrl\nbf/xkh41syPPc7+7/0ddugLQcFWH391flxRfsB4VyZvHv37zxWH9R2uzr42vgqezOw5kn7M/4we1\nnRP/7uz4nPt3T8+unfh/8Tb3wdY9dqJemOoDEkX4gUQRfiBRhB9IFOEHEkX4gURx6e4WkHdKbjiV\nJ2nuX2/IrPn7h6rqqRlqvfz15Lb4kudT2rPruVN5Jab6ABylCD+QKMIPJIrwA4ki/ECiCD+QKMIP\nJIp5/kq1V7+cdEke1qPLW0tSx774taO5/KNhKelMOXPxnsBcfS3Y8wOJIvxAogg/kCjCDySK8AOJ\nIvxAogg/kCjm+Y/IOTd899kTMmtndm0Nx+adr//84clhffzmsCw7/dTs2htxb6X3DsZPzlz5UYs9\nP5Aowg8kivADiSL8QKIIP5Aowg8kivADicqd5zezlZIul7TT3eeX7ztO0kOSZknaJOkqd3+ncW02\nngXXeJekvfOyz8mf1xmfM99lXWH9Y917w/pNN90f1l84eHJm7b61F4Rjp/0o/hGY/N3sNQEkaXDf\nvrCO1lXJnv9bki75wH03S1rj7nMkrSl/D2AUyQ2/uz8lac8H7l4iaVX59ipJS+vcF4AGq/Yz//Hu\nvl2Syl+n1a8lAM3Q8GP7zWy5pOWS1K1xjX45ABWqds+/w8ymS1L5686sB7r7CnfvdffeDsV/+ALQ\nPNWGf7WkZeXbyyQ9Vp92ADRLbvjN7AFJP5Z0upltMbPrJN0haZGZvSppUfl7AKNI7md+d78mo3Rx\nnXtpaR78mmxX9df0l6TxOccBfKonPoQiqt/8e+vCsY8tnBHWv3DulWF99uqcYxxeeSuzNrB1WzgW\njcURfkCiCD+QKMIPJIrwA4ki/ECiCD+QKC7dXSErZdcGc5bgztNujfsdPFadYf3q8bvC+qI/+HJY\nf/zS2WH99sc+lVmbc/uBcCynCzcWe34gUYQfSBThBxJF+IFEEX4gUYQfSBThBxLFPH+ZD8ZLUU/6\nWfZpu32HxodjF3S9l/PicbkWHRZfknyM4vrktrFh/doJ2afsSlL30gcza3/3ZtbZ4kNOWPlcWC8d\nzFleHCH2/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIp5/iNKOfP8L/8is/bNHb8djt006aWqWqqH\nM7u2hvV5nYfCet5lycdafL2AT4zbkln74sL4fP22700O6741vmy4DwyE9dSx5wcSRfiBRBF+IFGE\nH0gU4QcSRfiBRBF+IFHmHp9MbmYrJV0uaae7zy/fd5uk6yUduej7Le7+eN6LHWPH+QIbnSt7W1f2\nMtptvzYrHFvqbPDhFO3Zc/G7z54QDt07L/73H5wYH//wtxc9Etav6NmeWfvp4Xi7fOZrN4T1E3+w\nN6yXnt+YXcz5uR+t1voa7fM9Fa0ZX8me/1uSLhnh/q+6+znl/3KDD6C15Ibf3Z+StKcJvQBoolo+\n899gZi+Y2Uozm1S3jgA0RbXhv0vSaZLOkbRdUuaCbma23Mz6zKyvX/Fx5ACap6rwu/sOdx9095Kk\nuyWdHzx2hbv3untvh7L/aAaguaoKv5lNH/btFZLW16cdAM2SOwdlZg9IWihpipltkXSrpIVmdo6G\nLjq9SdKnG9gjgAbIneevp9E8zz9qtcXX5bf2uN7WE1+3f/fSM8L6uD/Knue/99fvDcf+18FTw/qX\n1i8O67NvfDezNvDGm+HY0are8/wAjkKEH0gU4QcSRfiBRBF+IFGEH0gUU32oiY2JDxWx+XMza9tu\ni3/2vn/e3WH99YF4afQ/+9pnMmsnrjg6l/9mqg9ALsIPJIrwA4ki/ECiCD+QKMIPJIrwA4liie46\nsI54meq2Y+L56NK+A2Hd++OlqIuUtwy2B5fPnvL188Kx//vPp4T1y8bFp+Ve+af/nf3cfReEY9ue\njo8DOBqw5wcSRfiBRBF+IFGEH0gU4QcSRfiBRBF+IFHM89dB2+yZYX37ouPD+tRn34uff92GsJ43\n116o4HoR3a/sCIf+y6aLwvqcuQ+H9euO7cus3bv44+HYWWvjYzda+diLSrHnBxJF+IFEEX4gUYQf\nSBThBxJF+IFEEX4gUbnz/GY2U9I9kk6QVJK0wt3vNLPjJD0kaZakTZKucvd3GtdqC+uIN2P35fF8\n9u7fjce3fe83w/qUn+7PLg7G18Zv3529jLUkDe7cFdZVyln3oS37EvKDUyaGQ8eOiXtrV/zaE9qy\nt2v/+OatV9GqKtnzD0i60d3nSbpA0mfN7AxJN0ta4+5zJK0pfw9glMgNv7tvd/dny7f3S9ooaYak\nJZJWlR+2StLSRjUJoP4+0md+M5sl6VxJayUd7+7bpaFfEJKm1bs5AI1TcfjNbLyk70j6nLvv+wjj\nlptZn5n19etQNT0CaICKwm9mHRoK/n3u/kj57h1mNr1cny5p50hj3X2Fu/e6e2+HuurRM4A6yA2/\nmZmkb0ja6O5fGVZaLWlZ+fYySY/Vvz0AjVLJKb0XSrpW0otmduR6xrdIukPSw2Z2naTNkq5sTIut\nzzdtCeu7nz8rrH/sd+JTdv/w8/Hv1bf6j82s9Xt7OPbfNi+In/ulc8O6SnE52r3Mmr8tHPrA3IfC\n+qS27rB+yPOaS1tu+N39aUlZk7UX17cdAM3CEX5Aogg/kCjCDySK8AOJIvxAogg/kCgu3V0Hpffi\nS2/P/cfNYX37908L63/55/FS1X911uOZtcvGvhaO/eP5Pw/rpfmNmyvvsPgYhDEa27DXBnt+IFmE\nH0gU4QcSRfiBRBF+IFGEH0gU4QcSxTx/Ewxs2RrW27bG57Wf+vMTw/o35yzJrH3h9+Olpr942bfD\n+uU98bUK2jPP9h7SFuxf+n0wHJvz1Ln6Do3LrHW9k7PfS+BaAOz5gUQRfiBRhB9IFOEHEkX4gUQR\nfiBRhB9IlLk3b6niY+w4X2Bc7buZ2o85Jqy/vfTMuH5W/PMxOCGeqx87+ReZtfe3jg/HTpuzO6yf\nOvHtsL7h2/Myayf9+xvh2LxjM1rVWl+jfb6noiMk2PMDiSL8QKIIP5Aowg8kivADiSL8QKIIP5Co\n3PP5zWympHsknaCh1dhXuPudZnabpOsl7So/9BZ3z76APAoxuG9fWD/23p+E9Unt8bX1rbMjro/v\nyayV9r4ajm2fOiWs7x07KayfuPW5zNrAwYPh2BRUcjGPAUk3uvuzZjZB0jNm9mS59lV3//vGtQeg\nUXLD7+7bJW0v395vZhslzWh0YwAa6yN95jezWZLOlbS2fNcNZvaCma00sxHfg5nZcjPrM7O+fh2q\nqVkA9VNx+M1svKTvSPqcu++TdJek0ySdo6F3Bl8eaZy7r3D3Xnfv7VBXHVoGUA8Vhd/MOjQU/Pvc\n/RFJcvcd7j7o7iVJd0s6v3FtAqi33PCbmUn6hqSN7v6VYfdPH/awKyStr397ABqlkr/2XyjpWkkv\nmtmRuZNbJF1jZudIckmbJH26IR2isUrxKbmeV+8/HD9/zvLlkdF6Wu1oUclf+5/WyFdQZ04fGMU4\nwg9IFOEHEkX4gUQRfiBRhB9IFOEHEkX4gUQRfiBRhB9IFOEHEkX4gUQRfiBRhB9IFOEHEtXUJbrN\nbJek4WsjT5EUr8NcnFbtrVX7kuitWvXs7RR3n1rJA5sa/g+9uFmfu/cW1kCgVXtr1b4keqtWUb3x\nth9IFOEHElV0+FcU/PqRVu2tVfuS6K1ahfRW6Gd+AMUpes8PoCCFhN/MLjGzl83sNTO7uYgespjZ\nJjN70cyeM7O+gntZaWY7zWz9sPuOM7MnzezV8td4qdrm9nabmW0tb7vnzOyygnqbaWb/Y2YbzWyD\nmf1F+f5Ct13QVyHbrelv+82sXdIrkhZJ2iJpnaRr3P1nTW0kg5ltktTr7oXPCZvZRZIOSLrH3eeX\n7/uSpD3ufkf5F+ckd/98i/R2m6QDRa/cXF5QZvrwlaUlLZX0Jypw2wV9XaUCtlsRe/7zJb3m7q+7\n+2FJD0paUkAfLc/dn5K05wN3L5G0qnx7lYZ+eJouo7eW4O7b3f3Z8u39ko6sLF3otgv6KkQR4Z8h\n6c1h329Ray357ZKeMLNnzGx50c2M4PjysulHlk+fVnA/H5S7cnMzfWBl6ZbZdtWseF1vRYR/pNV/\nWmnK4UJ3P0/SpZI+W357i8pUtHJzs4ywsnRLqHbF63orIvxbJM0c9v1JkrYV0MeI3H1b+etOSY+q\n9VYf3nFkkdTy150F9/NLrbRy80grS6sFtl0rrXhdRPjXSZpjZrPNrFPS1ZJWF9DHh5hZT/kPMTKz\nHkmL1XqrD6+WtKx8e5mkxwrs5Ve0ysrNWStLq+Bt12orXhdykE95KuMfJLVLWunutze9iRGY2aka\n2ttLQ4uY3l9kb2b2gKSFGjrra4ekWyV9V9LDkk6WtFnSle7e9D+8ZfS2UENvXX+5cvORz9hN7u23\nJP1Q0ouSSuW7b9HQ5+vCtl3Q1zUqYLtxhB+QKI7wAxJF+IFEEX4gUYQfSBThBxJF+IFEEX4gUYQf\nSNT/A3EzwVaOvbYWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00323816783869\n",
      "2368.28414797\n"
     ]
    }
   ],
   "source": [
    "# hessian vector product w.r.t. test image\n",
    "\n",
    "params = model.logits.parameters\n",
    "\n",
    "img_test, lb_test = test_set.__getitem__(1)\n",
    "show_image_from_data(img_test)\n",
    "\n",
    "print('ground truth label: ', anno_dict['classes'][str(np.argmax(lb_test))])\n",
    "print('network prediction: ', anno_dict['classes'][str(np.argmax(model.logits.eval({model.X:img_test})))])\n",
    "\n",
    "v_test = model.loss.grad({model.X:img_test, model.y:lb_test}, wrt=params)\n",
    "\n",
    "# HVP(y,x,v)\n",
    "img, lb = train_set.__getitem__(1)\n",
    "img.shape\n",
    "show_image_from_data(img)\n",
    "\n",
    "v_train = model.loss.grad({model.X:img, model.y:lb}, wrt=params)\n",
    "\n",
    "hvp = HVP(model.loss, {model.X:img, model.y:lb}, v_test)\n",
    "#model.logits.restore('/Data/checkpts/noisy/model_fold_1_trainval_ratio_1.0.dnn')\n",
    "\n",
    "print(grad_inner_product(hvp, v_test))\n",
    "print(grad_inner_product(v_test,v_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSNT/A3EzwVaOvbYWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursion depth: 0, norm: 48.66894139873618, time: 5.391250371932983 \n",
      "\n",
      "Recursion depth: 1, norm: 48.5362243354447, time: 5.441539287567139 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0618622361583979e-10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, lb = train_set.__getitem__(1)\n",
    "show_image_from_data(img)\n",
    "\n",
    "v_train = model.loss.grad({model.X:img, model.y:lb}, wrt=params)\n",
    "\n",
    "model.logits.restore('/Data/checkpts/noisy/model_fold_1_trainval_ratio_1.0.dnn')\n",
    "model.loss.eval({model.X: img, model.y:lb})\n",
    "\n",
    "ihvp = IHVP(model, model.loss, v_test, train_set)\n",
    "grad_inner_product(ihvp[0], v_train)/1000 # loss difference = -1/num_sample * influence function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IHVP를 구하면 발산함!\n",
    "\n",
    "아마 복잡한 network 때문일 수도 있음.\n",
    "\n",
    "따라서 단순한 closed-form이 있는 toy example을 만들고, 이에 대해서 해볼 것.\n",
    "(우선 잘 돌아가는지 확인하기 위해서)\n",
    "\n",
    "그리고 epoch 단위는 너무 큰 거일 수도 있음.\n",
    "따라서 step 단위로 바꿀 수 있게도 생각해볼 것\n",
    "\n",
    "step마다 얼마나 근접하는지도 check\n",
    "\n",
    "SE가 잘 동작하는데 복잡한 network 상황이기 때문에 안 되는 거라면 \n",
    "\n",
    "- convex relaxation of network (refer ICML)\n",
    "- frozen network (feature layer froze)\n",
    "- simple network (데이터가 얼마나 어려운지를(soft-label) 보는 것이기 때문에 굳이 현 네트워크일 필요는 없음. 따라서 정말 간단한 network를 만들고 학습하여 $\\hat{\\theta}$을 얻은 후 이를 가지고 IF를 구함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = \n",
      " [[-0.60081786]] \n",
      "w2 = \n",
      " [[ 0.65675038]] \n",
      "loss = \n",
      " [-3.20114636]\n",
      "hvp {Parameter('W', [], [1 x 1]): array([[ 6.89029694]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 7.43865967]], dtype=float32)}\n",
      "w1* = \n",
      " [[ 1.]] \n",
      "w2* = \n",
      " [[ 1.]]\n",
      "w^*: (array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)) loss: [-1.]\n",
      "\n",
      "###### ihvp start ######\n",
      "\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[-18.02444458]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-18.02444458]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ 20.02444458]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 20.02444458]], dtype=float32)}\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[-440.50216675]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-440.50216675]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ 461.52661133]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 461.52661133]], dtype=float32)}\n",
      "Recursion depth: 0, norm: 652.6971924254003, time: 0.12923860549926758 \n",
      "\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[-8307.60644531]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-8307.60644531]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ 8770.1328125]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 8770.1328125]], dtype=float32)}\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[-193482.578125]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-193482.578125]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ 202253.71875]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 202253.71875]], dtype=float32)}\n",
      "Recursion depth: 1, norm: 286029.95535432996, time: 0.19130277633666992 \n",
      "\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[-11068387.]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-11068387.]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ 11270642.]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 11270642.]], dtype=float32)}\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ -1.14554687e+12]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ -1.14554687e+12]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[  1.14555814e+12]], dtype=float32), Parameter('W', [], [1 x 1]): array([[  1.14555814e+12]], dtype=float32)}\n",
      "Recursion depth: 2, norm: 1620063820357.9084, time: 0.20438528060913086 \n",
      "\n",
      "#w: \n",
      " [array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ -1.20265577e+27]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ -1.20265577e+27]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[  1.20265577e+27]], dtype=float32), Parameter('W', [], [1 x 1]): array([[  1.20265577e+27]], dtype=float32)}\n",
      "#w: \n",
      " [array([[ 0.]], dtype=float32), array([[ 0.]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[-inf]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-inf]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ inf]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ inf]], dtype=float32)}\n",
      "Recursion depth: 3, norm: inf, time: 0.21805763244628906 \n",
      "\n",
      "#w: \n",
      " [array([[ nan]], dtype=float32), array([[ nan]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32)}\n",
      "#w: \n",
      " [array([[ nan]], dtype=float32), array([[ nan]], dtype=float32)] \n",
      "#hvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32)} \n",
      "#ihvp: \n",
      " {Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32)}\n",
      "Recursion depth: 4, norm: nan, time: 0.2174818515777588 \n",
      "\n",
      "[{Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwehee/anaconda3/envs/cntk/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: invalid value encountered in add\n"
     ]
    }
   ],
   "source": [
    "# toy example for IHVP: 1D example\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        #self.loss = C.reduce_l2(self.pred-self.y)\n",
    "        self.loss = -C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "    \n",
    "def HVP(y, x, v):\n",
    "    # Calculate Hessian vector product \n",
    "    # y: scalar function to be differentiated (function, e.g. cross entropy loss)\n",
    "    # x: feed_dict value for the network (dictionary, e.g. {model.X: image_batch, model.y: label_batch})\n",
    "    # v: vector to be producted (by Hessian) (numeric dictionary, e.g., g(z_test))\n",
    "    ## w: variables to differentiate (numeric, e.g. neural network weight)\n",
    "    \n",
    "    # hyperparameter r\n",
    "    r = 1e-5\n",
    "    \n",
    "    assert type(x)==dict, \"Input of HVP is wrong. This should be dictionary\"\n",
    "     \n",
    "    w = y.parameters\n",
    "    \n",
    "    # gradient for plus\n",
    "    weight_update(w, v, +r)\n",
    "    g_plus = y.grad(x, wrt=params)\n",
    "  \n",
    "    # gradient for minus\n",
    "    weight_update(w, v, -2*r)\n",
    "    g_minus = y.grad(x, wrt=params)\n",
    "    \n",
    "    # weight reconstruction\n",
    "    weight_update(w, v, +r)\n",
    "    \n",
    "    hvp = {ks: (g_plus[ks] - g_minus[ks])/(2*r) for ks in g_plus.keys()}\n",
    "       \n",
    "    return hvp\n",
    "    \n",
    "# stochastic estimation\n",
    "def IHVP(model, y, v, data_set, verbose=False): # data, network, etc. as we did in GradCAM\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    \n",
    "    # hyperparameters (hp_d)\n",
    "    recursion_depth = 5\n",
    "    scale = 1\n",
    "    damping = 0.0 # paper ref:0.01\n",
    "    batch_size = 1\n",
    "    num_samples = 1 # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "                #break\n",
    "                if verbose:\n",
    "                    print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "            print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "        \n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    return inv_hvps\n",
    "    \n",
    "    # average among samples\n",
    "    #ihvp = average(inv_hvps)\n",
    "    #return ihvp\n",
    "        \n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "params[0].value= np.array([[1.]],dtype=np.float32) # optimal weight w.r.t training points\n",
    "params[1].value= np.array([[1.]],dtype=np.float32) # optimal weight w.r.t training points\n",
    "\n",
    "print('w1* = \\n', params[0].value, '\\nw2* = \\n', params[1].value)\n",
    "print('w^*:', (params[0].value, params[1].value), 'loss:', net.loss.eval(x_feed))\n",
    "\n",
    "images = np.array([[2.],[2.]], dtype=np.float32)\n",
    "labels = np.array([[1.5],[.5]], dtype=np.float32)\n",
    "train_set = SimpleDataset(images, labels)\n",
    "\n",
    "print('\\n###### ihvp start ######\\n')\n",
    "ihvp = IHVP(net, net.loss, v_feed, train_set, verbose=True)\n",
    "\n",
    "print(ihvp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "애초에 stochastic estimation을 썼을 경우 잘 안되는 example.\n",
    "hvp가 아무리 잘 되어도 발산함.\n",
    "\n",
    "strictly convex\n",
    "\n",
    "$\n",
    "L(w) = -\\sum{(y_i - w_1 w_2 x_i)^2} \\\\\n",
    "\\text{Assume: single data point, (2,1)} \\\\\n",
    "L(w) = -(1-2 w_1 w_2)^2 \\\\\n",
    "H = -\\left[ {\\begin{array}{cc}\n",
    "   8w_2^2  & 16w_1w_2-4 \\\\\n",
    "   16w_1w_2-4 & 8w_1^2 \\\\\n",
    "  \\end{array} } \\right] \\\\\n",
    "H^{-1} = -\\frac{1}{64w_1^2w_2^2-(16w_1w_2-4)^2}\n",
    "\\left[ {\\begin{array}{cc}\n",
    "   8w_1^2  & -16w_1w_2-4 \\\\\n",
    "   -16w_1w_2-4 & 8w_2^2 \\\\\n",
    "  \\end{array} } \\right] \\\\\n",
    "\\text{Assume: (w_1,w_2)=(1,1)} \\\\\n",
    "H = -\\left[ {\\begin{array}{cc}\n",
    "   8  & 12 \\\\\n",
    "   12 & 8  \\\\\n",
    "  \\end{array} } \\right] \\\\\n",
    "H^{-1} = -\\frac{1}{20} \n",
    "\\left[ {\\begin{array}{cc}\n",
    "   2  & -3 \\\\\n",
    "   -3 & 2  \\\\\n",
    "  \\end{array} } \\right] \\\\\n",
    "\\text{Assume: v=[1.,1.]} \\\\\n",
    "H^{-1}v = (0.05, 0.05) \\\\\n",
    "$\n",
    "\n",
    "하지만 stochastic estimation으로 생각해보면, initial point는 (1,1)에서 hvp를 구하면 -(20, 20).\n",
    "현재 cur_estimate은 약 +(20,20)이 된다.\n",
    "이를 가지고 다시 hvp를 구하면 약 +(400, 400) 정도가 된다.\n",
    "이를 계속 반복하게 되면 발산하게 된다.\n",
    "\n",
    "따라서 이는 hvp에서 오차 때문에 발생한 문제가 아니라 stochastic estimation 자체의 불안정성 때문이라고 볼 수 있다.\n",
    "(참고: tensorflow의 tf.gradients를 사용해서 hvp를 구현할 경우, 오차가 거의 없는 상태로 hvp를 얻어낼 수 있다.)\n",
    "\n",
    "이후 conjugate gradient를 구현해서 실험해 볼 것이다.\n",
    "\n",
    "### CONVEX 문제가 아니었음. 해당 H의 eigen value를 구하면 20, -4가 나옴!\n",
    "\n",
    "w를 잘 잡으면 hessian을 convex하게 만들 수 있음. \n",
    "즉 특정 w에 대해서는 convex한 hessian을 얻을 수 있지만, 또 특정 w에 대해서는 convex하지 않음.\n",
    "만약 w를 고정해서 hessian matrix를 convex하게 잡고 난 다음엔 L로부터 inverse hessian vector product를 하는게 가능한가?\n",
    "\n",
    "HVP를 할 때 w를 $w+r*v$ 등으로 비틀어서 보게 되는데, 이런 경우 convex 하지 않으면 문제가 발생할 수도?\n",
    "는 아님!. 저건 그냥 미분 정의에서 나오는 거라서 convex 안해도 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient가 w가 1개일 경우 dictionary가 아니라 array가 됨. (일관성 무엇?)\n",
    "\n",
    "또 사실 w가 1개일 경우 hessian이 matrix가 아니기 때문에 너무 trivial한 경우라고 생각됨.\n",
    "\n",
    "### answer = 1/12 [[1.], [1.]]\n",
    "\n",
    "2차원에서 수렴하는거 step마다 찍기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가해볼 것\n",
    "\n",
    "- Hessian 보고 eigen value 구해서 positive definite인지 check.\n",
    "- 아니라면 warning message 추가하기. (이거 때문에 잘 못 되는건지 확인하기 위해서)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_inner_product(grad1, grad2):\n",
    "    # inner product for dictionary-format gradients (output scalar value)\n",
    "    \n",
    "    val = 0\n",
    "    \n",
    "    for ks in grad1.keys():\n",
    "        #C.inner(grad1[ks], grad2[ks])\n",
    "        val += np.sum(np.multiply(grad1[ks],grad2[ks]))\n",
    "        #val += np.dot(grad1[ks], grad2[ks])\n",
    "        \n",
    "    return val\n",
    "\n",
    "def weight_update(w, v, r):\n",
    "    # w: weights of neural network (tuple)\n",
    "    # v: value for delta w (dictionary, e.g., gradient value)\n",
    "    # r: hyperparameter for a gradient (scalar)\n",
    "\n",
    "    for p in w:\n",
    "        p.value += r * v[p]\n",
    "        \n",
    "def HVP(y, x, v):\n",
    "    # Calculate Hessian vector product \n",
    "    # y: scalar function to be differentiated (function, e.g. cross entropy loss)\n",
    "    # x: feed_dict value for the network (dictionary, e.g. {model.X: image_batch, model.y: label_batch})\n",
    "    # v: vector to be producted (by Hessian) (numeric dictionary, e.g., g(z_test))\n",
    "    ## w: variables to differentiate (numeric, e.g. neural network weight)\n",
    "    \n",
    "    # hyperparameter r\n",
    "    r = 1e-5\n",
    "    \n",
    "    assert type(x)==dict, \"Input of HVP is wrong. This should be dictionary\"\n",
    "     \n",
    "    w = y.parameters\n",
    "    \n",
    "    # gradient for plus\n",
    "    weight_update(w, v, +r)\n",
    "    g_plus = y.grad(x, wrt=params)\n",
    "  \n",
    "    # gradient for minus\n",
    "    weight_update(w, v, -2*r)\n",
    "    g_minus = y.grad(x, wrt=params)\n",
    "    \n",
    "    # weight reconstruction\n",
    "    weight_update(w, v, +r)\n",
    "    \n",
    "    hvp = {ks: (g_plus[ks] - g_minus[ks])/(2*r) for ks in g_plus.keys()}\n",
    "       \n",
    "    return hvp\n",
    "\n",
    "def HVP_minibatch_val(model, y, v, data_set):\n",
    "    # Calculate Hessian vector product w.r.t whole dataset\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    \n",
    "    # hyperparameters\n",
    "    damping = 0.0 # convexity term; paper ref:0.01\n",
    "    batch_size = 1\n",
    "    \n",
    "    hvp_batch = {ks: [] for ks in v.keys()}\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    for img, lb in dataloader:\n",
    "        img = img.numpy(); lb = lb.numpy()\n",
    "        x_feed = {model.X: img, model.y:lb}\n",
    "        hvp = HVP(y,x_feed,v)\n",
    "        # add hvp value\n",
    "        [hvp_batch[ks].append(hvp[ks]/img.shape[0]) for ks in hvp.keys()]\n",
    "        \n",
    "    hvp_mean = {ks: np.mean(hvp_batch[ks], axis=0) + damping*v[ks] for ks in hvp_batch.keys()}\n",
    "    \n",
    "    return hvp_mean\n",
    "\n",
    "from scipy.optimize import fmin_ncg\n",
    "\n",
    "# 정리정리!! 함수 인풋도 정리!\n",
    "# x: solution vector for conjugate gradient, whose shape is same as flattened gradient. NOT feed dict value\n",
    "\n",
    "def dic2vec(dic):\n",
    "    # convert a dictionary with matrix values to a 1D vector\n",
    "    # e.g. gradient of network -> 1D vector\n",
    "    vec = np.concatenate([val.reshape(-1) for val in dic.values()])\n",
    "    \n",
    "    return vec\n",
    "\n",
    "# Do we need this?\n",
    "#def vec2dic(vec, fmt):\n",
    "    # convert a 1D vector to a dictionary of format fmt\n",
    "    # fmt = {key: val.shape for (key,val) in dict}\n",
    "\n",
    "def get_fmin_loss_fn(model, y, data_set, v):\n",
    "    \n",
    "    def get_fmin_loss(x):\n",
    "        hvp_val = HVP_minibatch_val(model, y, x, data_set)\n",
    "        hvp_flat = dic2vec(hvp_val)\n",
    "        \n",
    "        return 0.5 * grad_inner_product(hvp_flat, x) - grad_inner_product(v, x)\n",
    "    \n",
    "    return get_fmin_loss\n",
    "\n",
    "def get_fmin_grad_fn(model, y, data_set, v):\n",
    "    \n",
    "    def get_fmin_grad(x):\n",
    "        hvp_val = HVP_minibatch_val(model, y, x, data_set)\n",
    "        hvp_flat = dic2vec(hvp_val)\n",
    "        v_flat = dic2vec(v)\n",
    "        \n",
    "        return hvp_flat - v_flat\n",
    "    \n",
    "    return get_fmin_grad\n",
    "\n",
    "def get_fmin_hvp(model, y, x, data_set):\n",
    "    hvp_val = HVP_minibatch_val(model, y, x, data_set)\n",
    "    hvp_flat = dic2vec(hvp_val)\n",
    "    \n",
    "    return hvp_flat\n",
    "\n",
    "def get_inverse_hvp_cg(model, y, data_set, v):\n",
    "    # return x, which is the solution whose value is H^-1 v\n",
    "    \n",
    "    fmin_loss_fn = get_fmin_loss_fn(model, y, data_set, v)\n",
    "    fmin_grad_fn = get_fmin_grad_fn(model, y, data_set, v)\n",
    "    \n",
    "    fmin_results = fmin_ncg(\\\n",
    "                           f = fmin_loss_fn,\\\n",
    "                           x0 = dic2vec(v),\\\n",
    "                           fprime = fmin_grad_fn,\n",
    "                           fhess_p = get_fmin_hvp,\\\n",
    "                           avextol = 1e-8,\\\n",
    "                           maxiter = 1e2)\n",
    "    \n",
    "    return fmin_results\n",
    "    #return vec2dic(fmin_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = \n",
      " [[ 0.23605482]] \n",
      "w2 = \n",
      " [[-0.94090229]] \n",
      "loss = \n",
      " [-2.08573985]\n",
      "hvp {Parameter('W', [], [1 x 1]): array([[ 0.47683716]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 7.10487366]], dtype=float32)}\n",
      "hvp_batch {Parameter('W', [], [1 x 1]): array([[ 0.47683716]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 7.10487366]], dtype=float32)}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-7a7b8c2a4538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hvp_batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHVP_minibatch_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inverse hvp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_inverse_hvp_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-171-813dde1b9d68>\u001b[0m in \u001b[0;36mget_inverse_hvp_cg\u001b[0;34m(model, y, data_set, v)\u001b[0m\n\u001b[1;32m     90\u001b[0m                            \u001b[0mfhess_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fmin_hvp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                            \u001b[0mavextol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                            maxiter = 1e2)\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmin_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin_ncg\u001b[0;34m(f, x0, fprime, fhess_p, fhess, args, avextol, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m     res = _minimize_newtoncg(f, x0, args, fprime, fhess, fhess_p,\n\u001b[0;32m-> 1461\u001b[0;31m                              callback=callback, **opts)\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_newtoncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, callback, xtol, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m     \u001b[0mgfk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m     \u001b[0mold_fval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m     \u001b[0mold_old_fval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \u001b[0mfloat64eps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cntk/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-813dde1b9d68>\u001b[0m in \u001b[0;36mget_fmin_loss\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_fmin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mhvp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHVP_minibatch_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mhvp_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhvp_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-813dde1b9d68>\u001b[0m in \u001b[0;36mHVP_minibatch_val\u001b[0;34m(model, y, v, data_set)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mhvp_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# toy example for IHVP: 1D example\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        #self.loss = C.reduce_l2(self.pred-self.y)\n",
    "        self.loss = -C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "    \n",
    "\n",
    "      \n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "images = np.asarray([[2.],[2.]], dtype=np.float32)\n",
    "labels = np.asarray([[1.],[1.]], dtype=np.float32)\n",
    "train_set = SimpleDataset(images,labels)\n",
    "\n",
    "print('hvp_batch', HVP_minibatch_val(net, net.loss, v_feed, train_set))\n",
    "\n",
    "print('inverse hvp', get_inverse_hvp_cg(net, net.loss, train_set, v_feed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HVP(y, x, v):\n",
    "    # Calculate Hessian vector product \n",
    "    # y: scalar function to be differentiated (function, e.g. cross entropy loss)\n",
    "    # x: feed_dict value for the network (dictionary, e.g. {model.X: image_batch, model.y: label_batch})\n",
    "    # v: vector to be producted (by Hessian) (numeric dictionary, e.g., g(z_test))\n",
    "    ## w: variables to differentiate (numeric, e.g. neural network weight)\n",
    "    \n",
    "    # hyperparameter r\n",
    "    r = 1e-2\n",
    "    \n",
    "    assert type(x)==dict, \"Input of HVP is wrong. this should be dictionary\"\n",
    "     \n",
    "    w = y.parameters\n",
    "    \n",
    "    # gradient for plus\n",
    "    weight_update(w, v, +r)\n",
    "    g_plus = y.grad(x, wrt=params)\n",
    "  \n",
    "    # gradient for minus\n",
    "    weight_update(w, v, -2*r)\n",
    "    g_minus = y.grad(x, wrt=params)\n",
    "    \n",
    "    # weight reconstruction\n",
    "    weight_update(w, v, +r)\n",
    "    \n",
    "    hvp = {ks: (g_plus[ks] - g_minus[ks])/(2*r) for ks in g_plus.keys()}\n",
    "       \n",
    "    return hvp\n",
    "\n",
    "# stochastic estimation\n",
    "def IHVP(model, y, v, data_set, verbose=False): # data, network, etc. as we did in GradCAM\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    \n",
    "    # hyperparameters (hp_d)\n",
    "    recursion_depth = 5\n",
    "    scale = 1\n",
    "    damping = 0.0 # paper ref:0.01\n",
    "    batch_size = 1\n",
    "    num_samples = 1 # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "                #break\n",
    "                if verbose:\n",
    "                    print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "            print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "        \n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    return inv_hvps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Parameter('W', [], [1 x 1]): array([[-0.68041325]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.7322467]], dtype=float32)} {Parameter('W', [], [1 x 1]): array([[-1.36082649]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-1.46449339]], dtype=float32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwehee/anaconda3/envs/cntk/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input3\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    }
   ],
   "source": [
    "gd1 = y.grad({x:np.array([[1.]])}, wrt=y.parameters)\n",
    "gd2 = y.grad({x:np.array([[1.],[1.]])}, wrt=y.parameters)\n",
    "print(gd1,gd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remark) gradient with minibatch whose size is greater than 1\n",
    "여러 sample에 대해서 gradient을 구하는 경우 average 대신 summation된 값을 내보냄.\n",
    "따라서 hvp를 sample 수에 대해서 normalize해줘야 함."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cntk]",
   "language": "python",
   "name": "conda-env-cntk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
