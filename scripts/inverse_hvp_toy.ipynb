{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from cntk.device import try_set_default_device, gpu\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hessian Vector Product (HVP)\n",
    "\n",
    "Implement HVP with numerical gradient method.\n",
    "\n",
    "i.e.\n",
    "\\begin{equation*}\n",
    "H(x)v = \\lim_{r\\rightarrow 0}{\\frac{g(x+rv)-g(x-rv)}{2r}}\n",
    "\\end{equation*}\n",
    "\n",
    "__cntk__에서는 gradient를 구할 때 operator 대신 numerical output이 나오게 되어, Hessian을 구할 때 __numerical approximation__을 사용할 수 밖에 없음.\n",
    "\n",
    "반면 __tensorflow__에서는 gradient가 operator가 되어, HVP을 tf.gradients를 두번 사용한 operator로 만들 수 있고, 이후 계산은 TF에서 지원해주는 __automatic differentiation__을 사용하기 때문에 정확한 HVP 값을 얻을 수 있다.\n",
    "\n",
    "## cf) automatic differentiation\n",
    "\n",
    "refer: \n",
    "- https://www.youtube.com/watch?v=pdSCHtPJ4B0\n",
    "- Automatic Differentiation in Machine Learning: A Survey, JMLR, 2018\n",
    "    - https://arxiv.org/pdf/1502.05767.pdf\n",
    "\n",
    "- symbolic differentiation: mathematica 등에서 사용되는 방법으로 sine, cosine 등의 미분식을 이용해서 symbol (x,y 등)에 대한 정확한 미분식을 얻는 방법. 변수가 복잡해질 수록 계산하는 것이 힘들어짐.\n",
    "- numerical differentiation: $\\frac{f(x+h)-f(x)}{h}$를 사용해서 미분값의 approximation을 찾는 방법. h가 작을 수록 미분값에 가까워지지만, round off error에 취약해짐.\n",
    "\n",
    "automatic differentiation은 SD, ND와 다른 방법론. 언어 내 내장 함수가 주어지면 이를 좀 더 최소 세분화된 node로 나눠 graph를 그리고, 이를 기반으로 미리 정의된 calculus rule을 적용해서 미분을 하는 방법. AD가 계산하는 방법은 forward mode, reverse mode 두 가지가 있으며 서로 장단점이 있음. 이는 각각 예시를 들어가며 설명하도록 함.\n",
    "\n",
    "e.g.\n",
    "\n",
    "(1) forward mode\n",
    "\n",
    "$y = f(x_1,x_2) = ln(x_1) + x_1x_2 - sin(x_2)$\n",
    "\n",
    "해당 식은 간단해보이지만 사실 더 세분화시켜 computational graph로 표현할 수 있음.\n",
    "\n",
    "![computational_graph](./images/computational_graph.png)\n",
    "\n",
    "각 노드가 의미하는 것은 다음 그림에서 확인할 수 있다. 위 node 단위로 나눠지게 되면 단순한 calculus rule을 사용해서 계산을 할 수 있다.\n",
    "\n",
    "![forward_mode](./images/forward_mode.png)\n",
    "\n",
    "오른쪽 표는 $x_1$에 대해서 미분을 진행한 것이다. i.e. $\\dot{v}_i = \\frac{\\partial v_i}{\\partial x_1}$. 차례로 계산하다보면 최종값($\\dot{v}_5$)은 과거의 node로 차근차근 표현해갈 수 있음을 확인할 수 있다. 중간중간 symbolic 미분은 $(a+b)' = a'+b'$나 $(ab)' = a'b + ab'$처럼 단순한 calculus이기 때문에 미리 정의를 해두고 필요시 불러오는 방법으로 진행된다. 때문에 $\\dot{v}_{-1}, \\dot{v}_{0}$부터 차례대로 계산한다면 최종 미분값까지 도달할 수 있다. y가 scalar가 아니라 vector의 값이더라도 forward pass를 한 번 진행하면 $x_1$에 관한 모든 미분값을 얻을 수 있다는 장점이 있다. 하지만 $x_2$에 대해 미분을 진행하려면 새로이 forward pass를 진행해야한다.\n",
    "__즉 input dimension이 작고 output dimension이 큰 경우 유리한 방법이다.__\n",
    "\n",
    "(2) reverse mode\n",
    "\n",
    "![reverse_mode](./images/reverse_mode.png)\n",
    "\n",
    "오른쪽 표는 최종 output $y$를 각 node $v_i$에 대해서 미분을 진행한 것이다. i.e. $\\bar{v}_i=\\frac{\\partial y}{\\partial v_i}$. 차례로 계산하다보면 최종값 $\\bar{x}_1, \\bar{x}_2$는 과거의 node로 차근차근 표현해갈 수 있음을 확인할 수 있다. 한 번의 진행과정으로 y를 $x_1, x_2$ 미분값을 동시에 얻을 수 있다. 하지만 y가 scalar가 아니라 vector인 경우 $y_1$, ..., $y_k$에 대해서 각각 진행해야한다. \n",
    "__즉 output dimension이 작고 input dimension이 큰 경우 유리한 방법이다.__\n",
    "\n",
    "$f: R^n \\rightarrow R^m$의 경우 Jacobian matrix $J \\in R^{m \\times n}$을 구할 때\n",
    "\n",
    "- Forward AD: $O(n \\times time(f))$\n",
    "- Reverse AD: $O(m \\times time(f))$\n",
    "\n",
    "시간이 들게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_inner_product(grad1, grad2):\n",
    "    # inner product for dictionary-format gradients (output scalar value)\n",
    "    \n",
    "    val = 0\n",
    "    \n",
    "    for ks in grad1.keys():\n",
    "        val += np.sum(np.multiply(grad1[ks],grad2[ks]))\n",
    "        \n",
    "    return val\n",
    "\n",
    "def weight_update(w, v, r):\n",
    "    # w: weights of neural network (tuple)\n",
    "    # v: value for delta w (dictionary, e.g., gradient value)\n",
    "    # r: hyperparameter for a gradient (scalar)\n",
    "\n",
    "    for p in w:\n",
    "        p.value += r * v[p]\n",
    "\n",
    "def HVP(y, x, v):\n",
    "    # Calculate Hessian vector product \n",
    "    # y: scalar function to be differentiated (function, e.g. cross entropy loss)\n",
    "    # x: feed_dict value for the network (dictionary, e.g. {model.X: image_batch, model.y: label_batch})\n",
    "    # v: vector to be producted (by Hessian) (numeric dictionary, e.g., g(z_test))\n",
    "    ## w: variables to differentiate (numeric, e.g. neural network weight)\n",
    "    \n",
    "    # hyperparameter r\n",
    "    r = 1e-2\n",
    "    \n",
    "    assert type(x)==dict, \"Input of HVP is wrong. this should be dictionary\"\n",
    "     \n",
    "    w = v.keys()\n",
    "    \n",
    "    # gradient for plus\n",
    "    weight_update(w, v, +r)\n",
    "    g_plus = y.grad(x, wrt=w)\n",
    "  \n",
    "    # gradient for minus\n",
    "    weight_update(w, v, -2*r)\n",
    "    g_minus = y.grad(x, wrt=w)\n",
    "    \n",
    "    # weight reconstruction\n",
    "    weight_update(w, v, +r)\n",
    "    \n",
    "    hvp = {ks: (g_plus[ks] - g_minus[ks])/(2*r) for ks in g_plus.keys()}\n",
    "       \n",
    "    return hvp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Parameter('W', [], [1 x 1]): array([[ 0.99999905]], dtype=float32),\n",
       " Parameter('W', [], [1 x 1]): array([[ 0.99999905]], dtype=float32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example for HVP\n",
    "\n",
    "x = C.input_variable(shape=(1,))\n",
    "h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(x)\n",
    "y = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(h)\n",
    "\n",
    "params = y.parameters\n",
    "x_feed = {x:[[1.]]}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "HVP(y, x_feed, v_feed)\n",
    "\n",
    "# output should be 1, 1\n",
    "# tensorflow version with double tf.gradients will outputs exactly (1., 1.) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow is not available\n"
     ]
    }
   ],
   "source": [
    "# hvp implementation for tensorflow\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    def HVP(y, x, v):\n",
    "        # y: scalar loss function\n",
    "        # w: weight vector in order to generate Hessian\n",
    "        # x: feed_dict value for input of the network\n",
    "        # v: vector to be producted (gradient dimension, i.e. list)\n",
    "        w = tf.trainable_variables(scope='network')\n",
    "\n",
    "        grads = tf.gradients(y, w)\n",
    "\n",
    "        grads_inner = grad_inner_product(grads, v)\n",
    "\n",
    "        hvp = tf.gradients(grads_inner, w)\n",
    "\n",
    "        hvp_val = list(map(lambda k: k.eval(x),hvp))\n",
    "\n",
    "        return hvp_val\n",
    "\n",
    "    def grad_inner_product(grad1, grad2):\n",
    "        # inner product for list-format gradients (output scalar value)\n",
    "\n",
    "        val = 0\n",
    "\n",
    "        for i in range(len(grad1)):\n",
    "            val += np.sum(np.multiply(grad1[i], grad2[i]))\n",
    "\n",
    "        return val\n",
    "\n",
    "    # toy example for HVP\n",
    "\n",
    "    with tf.variable_scope('network'):\n",
    "        x = tf.placeholder(tf.float32, (None, 1))\n",
    "        h = tf.layers.dense(x, 1, activation=None, use_bias=False)\n",
    "        y = tf.layers.dense(h, 1, activation=None, use_bias=False)\n",
    "\n",
    "    vars = tf.trainable_variables(scope='network')\n",
    "\n",
    "    tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    x_feed = {x: [[1.]]}\n",
    "    v_feed = [np.ones_like(p) for p in vars] # gradient_like one vector\n",
    "    print(v_feed)\n",
    "\n",
    "    hvp = HVP(y, x_feed, v_feed)\n",
    "    print('original hvp:', hvp)\n",
    "    print('concated hvp:', np.concatenate(hvp))\n",
    "\n",
    "    np.concatenate(hvp).shape\n",
    "\n",
    "except:\n",
    "    print('tensorflow is not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse HVP with Conjugate Gradient\n",
    "\n",
    "Implement conjugate gradient\n",
    "\n",
    "Conjugate gradient method 방법은 $x^* = H^{-1}v$를 구하고 싶은데, $H$ 차원이 너무 커서 직접적으로 matrix를 계산하고, 역행렬을 얻는 것이 힘들 때 \n",
    "\n",
    "\\begin{equation*}\n",
    "x^* = \\min_{x}{\\frac{1}{2}x^T H x - v^T x}\n",
    "\\end{equation*}\n",
    "\n",
    "를 $Hv$를 반복해서 사용함으로 해를 얻는 방법.\n",
    "\n",
    "때문에 quadratic programming 형태여야만 이론적 근거를 충족시킴.\n",
    "(refer: Krylov space)\n",
    "\n",
    "scipy package에서 제공하는 fmin_ncg는 임의의 convex 함수를 풀 때 conjugate gradient의 iteration 방법을 써서 풀겠다는 것. 주어진 objective function이 convex function 이라면 2nd order Taylor approximation을 할 수 있을 것이고 approximation을 하고 나면 정확하지는 않겠지만 어느정도 비슷하고 convergent한 해를 얻을 수 있다는 것. 따라서 fmin_ncg는 conjugate gradient의 iteration 방법으로 optimization 문제를 풀겠다는 것. \n",
    "\n",
    "이렇게 풀 경우에는 Hessian을 직접적으로 구하지 않고 (HVP만 사용해서) Newton's method 방식으로 optimize가 될 것.\n",
    "\n",
    "cf) 좀 더 general하게 설계되어있다 정도만 알면 됨. 어차피 우리는 objective function에 quadratic function을 넣을거고 그러면 전혀 문제 없음.\n",
    "\n",
    "Scipy package의 fmin conjugate gradient는 HVP 함수를 explicit하게 제공하면 더 정확하게 풀 수 있음. 따라서 위의 HVP를 사용할 예정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical Backgrounds\n",
    "-----------------------\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "#### Krylov Subspace \n",
    "\n",
    "Notations\n",
    "\n",
    "- $f(x) \\overset{def}{=} \\frac{1}{2}x^TAx - b^Tx$\n",
    "- $K_k \\overset{def}{=} span\\{b,Ab, \\ldots, A^{k-1}b\\}$; called Krylov subspace\n",
    "- $x^k \\overset{def}{=} \\arg{\\min_{x\\in K_k}{f(x)}}$; called Krylov sequence\n",
    "- $r^k \\overset{def}{=} b - Ax^k = -\\nabla f(x^k)$; called residual\n",
    "\n",
    "Properties\n",
    "\n",
    "1. $f(x^{k+1}) \\le f(x^k)$\n",
    "2. $x^n = x^*$\n",
    "3. $x^{k+1} = x^k + \\alpha_k r^k + \\beta_k (x^k - x^{k-1})$ for some $\\alpha_k, \\beta_k$\n",
    "\n",
    "__inverse Hessian vector product를 구할 때 Hessian vector product를 사용한 점화식을 반복하면 해를 얻을 수 있다.__\n",
    "\n",
    "#### Caley-Hamilton Theorem\n",
    "\n",
    "$\\chi(A) = A^n + \\alpha_1 A^{n-1} + \\cdots + \\alpha_n I = 0$\n",
    "\n",
    "where $\\alpha_i$ comes from characteristic polynomial of A.\n",
    "\n",
    "This theorem indicates that\n",
    "\n",
    "$A^{-1} = -\\frac{1}{\\alpha_n}A^{n-1} - \\frac{\\alpha_1}{\\alpha_n}A^{n-2} - \\cdots - \\frac{\\alpha_{n-1}}{\\alpha_n}I$\n",
    "\n",
    "점화식을 n번 반복하면 정확한 해를 얻을 수 있다. (Property (2) 증명)\n",
    "\n",
    "#### Settings\n",
    "\n",
    "Given, \n",
    "\n",
    "\\begin{align*}\n",
    "& \\hat{\\theta} \\in \\mathbb{R}^p \\\\\n",
    "& v = \\nabla L(z_{test}, \\hat{\\theta}) \\in \\mathbb{R}^p \\\\\n",
    "& H = \\frac{1}{n}\\sum_{i=0}^{n}{\\nabla^2 L(z_i,\\hat{\\theta})} \\in \\mathbb{R}^{p^2}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Our goal is to find $x^* \\rightarrow H^{-1}v$\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "> $x:= 0, r:= v, \\rho_0 := \\lvert\\lvert r \\rvert\\rvert ^2$\n",
    "\n",
    "> for $ k=1,\\ldots , N_{max} $\n",
    "\n",
    ">> if $\\sqrt{\\rho_{k-1}}\\le \\epsilon \\lvert\\lvert v \\rvert\\rvert$ : break\n",
    "\n",
    ">> if $k=1$ then $p := r$; else $p:=r+\\left( \\frac{\\rho_{k-1}}{\\rho_{k-2}} \\right) p$\n",
    "\n",
    ">> $w := Hp$\n",
    "\n",
    ">> $\\alpha := \\frac{\\rho_{k}}{p^Tw}$\n",
    "\n",
    ">> $x:=x+\\alpha p$\n",
    "\n",
    ">> $r := r-\\alpha w$\n",
    "\n",
    ">> $\\rho_{k}:=\\lvert\\lvert r \\rvert\\rvert ^2$\n",
    "\n",
    "Remark) \n",
    "- $w := Hp$ 진행할 때 HVP를 사용하면 $O(np)$만큼 computational complexity 듬.\n",
    "- 실제 code에서는 모든 training dataset에 대해서 HVP를 하려면 한번에 모든 training set에 대해서 feed_dict해줘야하기 때문에 메모리 문제로 HVP_minibatch를 구현함. (밑 코드 참고)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_ncg\n",
    "\n",
    "def HVP_minibatch_val(model, y, v, data_set):\n",
    "    # Calculate Hessian vector product w.r.t whole dataset\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (numeric dictionary, e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    \n",
    "    # hyperparameters\n",
    "    damping = 0.0 # convexity term; paper ref:0.01\n",
    "    batch_size = 1\n",
    "    \n",
    "    hvp_batch = {ks: [] for ks in v.keys()}\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    for img, lb in dataloader:\n",
    "        img = img.numpy(); lb = lb.numpy()\n",
    "        x_feed = {model.X: img, model.y:lb}\n",
    "        hvp = HVP(y,x_feed,v)\n",
    "        # add hvp value\n",
    "        [hvp_batch[ks].append(hvp[ks]/img.shape[0]) for ks in hvp.keys()]\n",
    "        \n",
    "    hvp_mean = {ks: np.mean(hvp_batch[ks], axis=0) + damping*v[ks] for ks in hvp_batch.keys()}\n",
    "    \n",
    "    return hvp_mean\n",
    "\n",
    "# x: solution vector for conjugate gradient, whose shape is same as flattened gradient. NOT feed dict value\n",
    "\n",
    "def dic2vec(dic):\n",
    "    # convert a dictionary with matrix values to a 1D vector\n",
    "    # e.g. gradient of network -> 1D vector\n",
    "    vec = np.concatenate([val.reshape(-1) for val in dic.values()])\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def vec2dic(vec, fmt):\n",
    "    # convert a 1D vector to a dictionary of format fmt\n",
    "    # fmt = {key: val.shape for (key,val) in dict}\n",
    "    \n",
    "    fmt_idx = [np.prod(val) for val in fmt.values()]\n",
    "    #lambda ls, idx: [ls[sum(idx[:i]):sum(idx[:i+1])] for i in range(len(idx))]\n",
    "    vec_split = [vec[sum(fmt_idx[:i]):sum(fmt_idx[:i+1])] for i in range(len(fmt_idx))]\n",
    "    dic = {key: vec_split[i].reshape(shape) for (i,(key,shape)) in enumerate(fmt.items())}\n",
    "\n",
    "    return dic\n",
    "\n",
    "\n",
    "def get_fmin_loss_fn(model, y, v, data_set):\n",
    "    \n",
    "    def get_fmin_loss(x):\n",
    "        x_dic = vec2dic(x, {key: val.shape for (key, val) in v.items()})\n",
    "        hvp_val = HVP_minibatch_val(model, y, x_dic, data_set)\n",
    "        \n",
    "        return 0.5 * grad_inner_product(hvp_val, x_dic) - grad_inner_product(v, x_dic)\n",
    "    \n",
    "    return get_fmin_loss\n",
    "\n",
    "def get_fmin_grad_fn(model, y, v, data_set):\n",
    "    \n",
    "    def get_fmin_grad(x):\n",
    "        # x: 1D vector\n",
    "        x_dic = vec2dic(x, {key: val.shape for (key, val) in v.items()})\n",
    "        hvp_val = HVP_minibatch_val(model, y, x_dic, data_set)\n",
    "        hvp_flat = dic2vec(hvp_val)\n",
    "        v_flat = dic2vec(v)\n",
    "        \n",
    "        return hvp_flat - v_flat\n",
    "    \n",
    "    return get_fmin_grad\n",
    "\n",
    "def get_fmin_hvp_fn(model, y, v, data_set):\n",
    "\n",
    "    def get_fmin_hvp(x, p):\n",
    "        p_dic = vec2dic(p, {key: val.shape for (key, val) in v.items()})\n",
    "        hvp_val = HVP_minibatch_val(model, y, p_dic, data_set)\n",
    "        hvp_flat = dic2vec(hvp_val)\n",
    "\n",
    "        return hvp_flat\n",
    "    \n",
    "    return get_fmin_hvp\n",
    "\n",
    "def get_inverse_hvp_cg(model, y, v, data_set):\n",
    "    # return x, which is the solution of QP, whose value is H^-1 v\n",
    "    \n",
    "    fmin_loss_fn = get_fmin_loss_fn(model, y, v, data_set)\n",
    "    fmin_grad_fn = get_fmin_grad_fn(model, y, v, data_set)\n",
    "    fmin_hvp_fn = get_fmin_hvp_fn(model, y, v, data_set)\n",
    "    \n",
    "    fmin_results = fmin_ncg(\\\n",
    "            f = fmin_loss_fn,\\\n",
    "            x0 = dic2vec(v),\\\n",
    "            fprime = fmin_grad_fn,\\\n",
    "            fhess_p = fmin_hvp_fn,\\\n",
    "            avextol = 1e-8,\\\n",
    "            maxiter = 1e2)\n",
    "    \n",
    "    return fmin_results\n",
    "    #return vec2dic(fmin_results, {key: val.shape for (key, val) in v.items()}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy의 conjugate gradient을 이용해서 구현하였다. \n",
    "\n",
    "fmin_ncg의 input으로는\n",
    "\n",
    "- f: objective function to be minimized ~ $f(x)=\\frac{1}{2}x^T H x - v^T x$ where $H\\triangleq \\frac{1}{n}\\sum_{i=0}^{n}{\\nabla^2 L(z_i,x)}$\n",
    "- x0: initial guess\n",
    "- fprime: gradient of f ~ $f(x)=H x - v$\n",
    "- fhess_p: function to compute the Hessian matrix of f ~ $f(x,p)=H p$\n",
    "- callback: an optional user-supplied function which is called after each iteration\n",
    "- avextol: hyperparameter epsilon \n",
    "- maxiter: maximum number of iterations to perform\n",
    "\n",
    "이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Example\n",
    "\n",
    "- __Set__ Training Set: \n",
    "$\\mathbb{T} = \\{(2,1)\\}$\n",
    "\n",
    "- Network Architecture: \n",
    "$\\hat{y} = w_1 w_2 x$\n",
    "\n",
    "- Loss Function: \n",
    "$L(w) = \\sum_{(x^{(i)},y^{(i)})\\in\\mathbb{T}}{(y^{(i)}_1 - (w_1 w_2 x^{(i)}))^2} = 4w_1^2w_2^2 -4w_1w_2 +1$\n",
    "\n",
    "- Hessian: \n",
    "$\n",
    "H(w) = \\left[ {\\begin{array}{cc}\n",
    "   8w_2^2  & 16w_1w_2-4 \\\\\n",
    "   16w_1w_2-4 & 8w_1^2 \\\\\n",
    "  \\end{array} } \\right] \\\\\n",
    "$\n",
    "\n",
    "cf) check the graph here\n",
    "\n",
    "https://www.google.co.kr/search?ei=evtoW5m5JpTe8wWggLqAAQ&q=%281-2*x*y%29%5E2&oq=%281-2*x*y%29%5E2&gs_l=psy-ab.3..0i7i30k1j0i30k1j0i7i5i30k1j0i8i30k1l4j0i5i30k1l2j0i8i30k1.5016.5780.0.6095.2.2.0.0.0.0.129.249.0j2.2.0....0...1c.1.64.psy-ab..0.2.248...0i8i7i30k1.0.tJbFx39Pz_s\n",
    "\n",
    "For some $(w_1,w_2)$, loss function is not convex.\n",
    "\n",
    "- __Set__ Network Parameter: \n",
    "$(w_1,w_2) = (1,\\frac{1}{3})$\n",
    "\n",
    "- Value of Hessian:\n",
    "$\n",
    "H = H((w_1,w_2)=(1,\\frac{1}{3})) = \\left[ {\\begin{array}{cc}\n",
    "   \\frac{8}{9}  & \\frac{4}{3} \\\\\n",
    "   \\frac{4}{3} & 8 \\\\\n",
    "  \\end{array} } \\right] \\\\\n",
    "$\n",
    "\n",
    "- Characteristic polynomial of H:\n",
    "$\\det{(H-\\lambda I)} = \\lambda^2 - \\frac{80}{9}\\lambda + \\frac{48}{9}$\n",
    "\n",
    "indicating that $L$ is locally convex under $(w_1,w_2) = (1,\\frac{1}{3})$.\n",
    "\n",
    "- Inverse Hessian:\n",
    "$H^{-1} = \\left[ {\\begin{array}{cc}\n",
    "   \\frac{3}{2}  & -\\frac{1}{4} \\\\\n",
    "   -\\frac{1}{4} & \\frac{1}{6} \\\\\n",
    "  \\end{array} } \\right] \\\\$\n",
    "  \n",
    "- __Set__ vector:\n",
    "$ v = [1., 1.]^T $\n",
    "\n",
    "- Inverse Hessian Vector Product:\n",
    "$ H^{-1}v = [\\frac{5}{4}, -\\frac{1}{12}]^T \\approx [1.25, -0.083]^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = \n",
      " [[ 0.11753198]] \n",
      "w2 = \n",
      " [[ 0.80720806]] \n",
      "loss = \n",
      " [ 0.65651226]\n",
      "w1 = \n",
      " [[ 1.]] \n",
      "w2 = \n",
      " [[ 0.33333334]] \n",
      "loss = \n",
      " [ 0.1111111]\n",
      "hvp {Parameter('W', [], [1 x 1]): array([[ 2.22302079]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 9.33413506]], dtype=float32)}\n",
      "hvp_batch {Parameter('W', [], [1 x 1]): array([[ 2.22302151]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 9.33413506]], dtype=float32)}\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.583326\n",
      "         Iterations: 4\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 14\n",
      "         Hessian evaluations: 7\n",
      "inverse hvp [ 1.24996972 -0.08331382]\n"
     ]
    }
   ],
   "source": [
    "# toy example for IHVP: 1D example\n",
    "\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        self.loss = C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "\n",
    "\n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "params[0].value = np.asarray([[1.]])\n",
    "params[1].value = np.asarray([[1./3.]])\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "images = np.asarray([[2.],[2.]], dtype=np.float32)\n",
    "labels = np.asarray([[1.],[1.]], dtype=np.float32)\n",
    "#images = np.asarray([[2.]], dtype=np.float32)\n",
    "#labels = np.asarray([[1.]], dtype=np.float32)\n",
    "\n",
    "train_set = SimpleDataset(images,labels)\n",
    "\n",
    "print('hvp_batch', HVP_minibatch_val(net, net.loss, v_feed, train_set))\n",
    "\n",
    "print('inverse hvp', get_inverse_hvp_cg(net, net.loss, v_feed, train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse HVP with Stochastic Estimation\n",
    "\n",
    "Implementation of IHVP with SE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical Backgrounds\n",
    "-----------------------\n",
    "\n",
    "Taylor series expansion을 통해서 \n",
    "\n",
    "\\begin{equation*}\n",
    "H_j^{-1}\\triangleq \\sum_{i=0}^{j}{(I-H)^i}\n",
    "\\end{equation*}\n",
    "\n",
    "Hessian matrix의 inverse를 approximate할 수 있다. 이 식을 새로 정리하면 다음과 같은 점화식을 얻을 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "H_j^{-1} = I + (I-H)H_{j-1}^{-1}\n",
    "\\end{equation*}\n",
    "\n",
    "우리는 이 점화식을 반복하여 진행하며 Hessian의 inverse를 추정할 것이다. 이 점화식을 반복하기 위해서는 H를 계산해야한다. 이 때 H는 $\\frac{1}{n}\\sum_{i=0}^n{\\nabla^2L(z_i,\\hat{\\theta}})$ 값으로 이 값 정확하게 구하려면 지나치게 많은 계산량을 필요로 한다. 때문에 이를 unbiased estimator인 $\\nabla^2L(z_i,\\hat{\\theta})$로 대처하여 iteration을 진행할 것이라는게 논문의 내용이다. 이 때 unbiased estimator of Hessian을 $\\tilde{H}$라고 하자. 실제 구현 코드에서는 unbiased estimator $\\tilde{H}$를 좀 더 잘 (낮은 variance로 추정하기) 구하기 위해서 몇 가지 방법을 제시하고 있다.\n",
    "\n",
    "#### Minibatching\n",
    "하나의 sample만을 가지고 unbiased estimator를 사용하는 대신, 여러 sampling에 대해서 평균취하는 방법이다. 평균을 취했기 때문에 mean값에는 변화가 없고, variance는 줄어들 것으로 기대할 수 있다. 이 때 sample 수는 $m$개이고 당연히 $m<<n$이다. e.g., Gaussian random variable이라고 가정할 경우 mean은 변함없고, variance는 $\\frac{1}{m^2}$로 줄어들 것이다. \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\tilde{H} \n",
    "&=& \\nabla^2L(z_i,\\hat{\\theta})\\\\\n",
    "&\\rightarrow& \\frac{1}{m}\\sum_{i=0}^m{\\nabla^2L(z\\_i,\\hat{\\theta}})\n",
    "\\end{eqnarray*}\n",
    "\n",
    "#### Scaling\n",
    "H를 추정하는 대신 $H'\\triangleq\\frac{H}{Scale}$을 추정하는 것이다. 상수배로 나뉘었기 때문에 variance가 줄어들 것이라고 예측할 수 있다. e.g., Gaussian random variable이라고 가정할 경우 variance가 $\\frac{1}{Scale^2}$ 만큼 줄어들 것이다. 이는 minibatching과 다르게 하나의 step에서 실질적인 계산량은 변함없이 정확도를 향상시킬 수 있다. 하지만 수렴을 위해서 더 많은 recursion step (j)을 요구한다. 때문에 scaling factor는 learning rate와도 연관지어 생각할 수 있다.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "{H'}_j^{-1} \n",
    "&=& I + (I-H'){H'}_{j-1}^{-1}\\\\\n",
    "&=& I + (I-\\frac{H}{Scale}){H'}_{j-1}^{-1}\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "그리고 이 값은 ${H'}_j^{-1}=\\left(\\frac{H_j}{Scale}\\right)^{-1}$를 추정한 것이기 때문에 $H_j^{-1}$을 얻기위해선 iteration을 통해 얻은 최종 값을 Scale값으로 나눠야한다.\n",
    "\n",
    "cf) Talor expansion이기 때문에 initialization 값은 변함이 없다, i.e., ${H'}_0^{-1}=I$.\n",
    "\n",
    "#### Damping\n",
    "마지막으로 code에는 damping term이 있다. 이 term은 앞서 Influence function을 얻을 때 strictly convex와 twice differentiable이라는 두 조건 중 strictly convex 조건을 더 강력하게 맞추기위해서 생겨난 regularization term이다. 특히 deep neural network 같은 경우에는 비용함수가 strictly convex라는 보장이 전혀 없기 때문에 꼭 필요한 term이다.\n",
    "\n",
    "정확하게 말하자면 positive eigenvalue를 얻기위해 임의로 identity matrix를 더해주는 것으로 수식으로 표현하자면 다음과 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\bar{H}=\\tilde{H}+\\lambda I\n",
    "\\end{equation*}\n",
    "\n",
    "이 $\\bar{H}$를 점화식에 넣게 되면 다음과 같은 식을 얻을 수 있다.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "H_j^{-1} \n",
    "&=& I + (I-\\bar{H})H_{j-1}^{-1}\\\\\n",
    "&=& I + \\left((1-\\lambda)I-\\tilde{H}\\right)H_{j-1}^{-1}\\\\\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementations\n",
    "---------------\n",
    "이 방법을 통해서 찾고자하는 최종 값은 $\\theta$와 차원이 같은 임의의 vector $v$와 Inverse of Hessian matrix의 곱, $H^{-1}v$ 값이다.\n",
    "따라서 위 점화식의 양 변에 $v$를 곱하고 추정할 vector를 $s_j$로 새로 정의하면, $\\text{i.e., } s_j \\triangleq H_j^{-1}v$, 다음과 같은 반복식을 얻을 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "s_j = v + s_{j-1} - \\bar{H} s_{j-1}\n",
    "\\end{equation*}\n",
    "\n",
    "Strictly convex 조건을 만족하기위해서 damping term을 풀면 다음과 같은 식을 얻을 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "s_j = v + (1-\\gamma)s_{j-1} - \\tilde{H} s_{j-1}\n",
    "\\end{equation*}\n",
    "\n",
    "위에서 설명한 minibatching과 scaling을 포함하여 점화식을 얻으면 다음과 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "{s'}_j = v + (1-\\gamma){s'}_{j-1} - \\frac{\\frac{1}{m}\\sum_{i=0}^m{\\nabla^2L(z\\_i,\\hat{\\theta}})}{Scale} {s'}_{j-1} \\text{ where } {s'}_j = Scale \\cdot s_j \n",
    "\\end{equation*}\n",
    "\n",
    "실제 구현된 코드의 input과 theoretical background의 hyperparameter들과 관련하여 설명하자면\n",
    "\n",
    "1. $\\gamma \\leftarrow$ damping : logistic regression 같이 strictly convex한 loss를 사용할 경우 0.0으로 두면 된다. 논문에서는 $\\lambda=0.01$로 사용해서 CNN network를 재 조정했다. \n",
    "\n",
    "2. $Scale \\leftarrow$ scale : 앞서 설명했듯 H에 대해서 iteration을 반복할 때 H를 scale로 나눠서 진행하는 것. vector s의 변화량이 줄어들기 때문에 variance가 줄어들 수 있겠지만 더 많은 recursion step이 필요할 것이다. recursion step을 거쳐서 얻은 후 다시 scale로 나누는 것을 잊지 말 것.\n",
    "\n",
    "3. $m \\leftarrow$ batch_size : 여러 sample을 사용하여 평균취하는 것으로 unbiased estimator를 얻은 것. 클 수록 좋겠지만 rtp * batch_size만큼 계산량이 느는 것이라 주의해야함. 실제 구현 단계에서는 total loss 자체가 minibatch에 대해서 reduce sum한 것이기 때문에 feed_dict만 minibatch wise로 하면 된다.\n",
    "\n",
    "$O(rtp)$\n",
    "\n",
    "$r$: num_samples\n",
    "\n",
    "$t$: recursion_depth\n",
    "\n",
    "$p$: dimension of $\\theta$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stochastic estimation\n",
    "def get_inverse_hvp_se(model, y, v, data_set, **kwargs):\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    # kwargs: hyperparameters for stochastic estimation\n",
    "    recursion_depth = kwargs.pop('recursion_depth', 50) # epoch\n",
    "    scale = kwargs.pop('scale', 1e1) # similar to learning rate\n",
    "    damping = kwargs.pop('damping', 0.0) # paper reference: 0.01\n",
    "    batch_size = kwargs.pop('batch_size', 1)\n",
    "    num_samples = kwargs.pop('num_samples', 1) # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    verbose = kwargs.pop('verbose', False)\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    params = v.keys()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "            if verbose:\n",
    "                print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "                print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "        \n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    inv_hvp_val = {ks: np.mean([inv_hvps[i][ks] for i in range(num_samples)], axis=0) for ks in inv_hvps[0].keys()}\n",
    "    \n",
    "    return inv_hvp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = \n",
      " [[ 0.3461298]] \n",
      "w2 = \n",
      " [[ 0.5710966]] \n",
      "loss = \n",
      " [ 0.36560512]\n",
      "w1 = \n",
      " [[ 1.]] \n",
      "w2 = \n",
      " [[ 0.33333334]] \n",
      "loss = \n",
      " [ 0.1111111]\n",
      "hvp {Parameter('W', [], [1 x 1]): array([[ 2.22302079]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 9.33413506]], dtype=float32)}\n",
      "inverse hvp {Parameter('W', [], [1 x 1]): array([[ 1.24517536]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.08125092]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# toy example for IHVP: 1D example\n",
    "\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        #self.loss = C.reduce_l2(self.pred-self.y)\n",
    "        self.loss = C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "\n",
    "\n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "params[0].value = np.asarray([[1.]])\n",
    "params[1].value = np.asarray([[1./3.]])\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "images = np.asarray([[2.],[2.]], dtype=np.float32)\n",
    "labels = np.asarray([[1.],[1.]], dtype=np.float32)\n",
    "#images = np.asarray([[2.]], dtype=np.float32)\n",
    "#labels = np.asarray([[1.]], dtype=np.float32)\n",
    "\n",
    "train_set = SimpleDataset(images,labels)\n",
    "\n",
    "print('inverse hvp', get_inverse_hvp_se(net, net.loss, v_feed, train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = \n",
      " [[ 0.50877059]] \n",
      "w2 = \n",
      " [[ 0.55213112]] \n",
      "loss = \n",
      " [ 0.19200508]\n",
      "w1 = \n",
      " [[ 1.]] \n",
      "w2 = \n",
      " [[ 0.33333334]] \n",
      "loss = \n",
      " [ 0.1111111]\n",
      "hvp {Parameter('W', [], [1 x 1]): array([[ 2.22302079]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 9.33413506]], dtype=float32)}\n",
      "scale20: {Parameter('W', [], [1 x 1]): array([[ 1.19857621]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.07018896]], dtype=float32)}\n",
      "scale10: {Parameter('W', [], [1 x 1]): array([[ 1.24517429]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.08125068]], dtype=float32)}\n",
      "scale5: {Parameter('W', [], [1 x 1]): array([[ 1.24909544]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.08285888]], dtype=float32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwehee/anaconda3/envs/cntk/lib/python3.5/site-packages/ipykernel/__main__.py:17: RuntimeWarning: invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale1: {Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ nan]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# graphical analysis of stochastic estimation \n",
    "\n",
    "def plot_inverse_hvp_se(model, y, v, data_set, **kwargs):\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # AND plot the process of convergence w.r.t. 2D space\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    # kwargs: hyperparameters for stochastic estimation\n",
    "    recursion_depth = kwargs.pop('recursion_depth', 100) # epoch\n",
    "    scale = kwargs.pop('scale', 1e1) # similar to learning rate\n",
    "    damping = kwargs.pop('damping', 0.0) # paper reference: 0.01\n",
    "    batch_size = kwargs.pop('batch_size', 1)\n",
    "    num_samples = kwargs.pop('num_samples', 1) # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    verbose = kwargs.pop('verbose', False)\n",
    "    graphics = kwargs.pop('graphics', True)\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    pts = [] # graphical points\n",
    "    # pts.append(dic2vec(v))\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "            if verbose:\n",
    "                print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "                print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "            if graphics:\n",
    "                curv = dic2vec(cur_estimate)/scale\n",
    "                if np.isnan(curv).any() or (np.abs(curv)>1e1).any():\n",
    "                    pts.append(1e1*np.ones_like(curv))\n",
    "                else:\n",
    "                    pts.append(curv)\n",
    "\n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    inv_hvp_val = {ks: np.mean([inv_hvps[i][ks] for i in range(num_samples)], axis=0) for ks in inv_hvps[0].keys()}\n",
    "    \n",
    "    return inv_hvp_val, pts\n",
    "\n",
    "# toy example for IHVP: 1D example\n",
    "\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        self.loss = C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "\n",
    "\n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "params[0].value = np.asarray([[1.]])\n",
    "params[1].value = np.asarray([[1./3.]])\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "#images = np.asarray([[2.],[2.]], dtype=np.float32)\n",
    "#labels = np.asarray([[1.],[1.]], dtype=np.float32)\n",
    "images = np.asarray([[2.]], dtype=np.float32)\n",
    "labels = np.asarray([[1.]], dtype=np.float32)\n",
    "\n",
    "train_set = SimpleDataset(images,labels)\n",
    "\n",
    "tmp, pts_scale20 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'scale':20})\n",
    "print('scale20:', tmp)\n",
    "tmp, pts_scale10 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'scale':10})\n",
    "print('scale10:', tmp)\n",
    "tmp, pts_scale5 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'scale':5})\n",
    "print('scale5:', tmp)\n",
    "tmp, pts_scale1 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'scale':1})\n",
    "print('scale1:', tmp)\n",
    "\n",
    "#print(pts_scale1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = -0.01; y0 = 0.01\n",
    "\n",
    "# total\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(len(pts_scale10)):\n",
    "    blk, = plt.plot(*pts_scale20[i], 'k.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale20[i]+np.array([x0,y0])), str(i), color='k')\n",
    "\n",
    "    blu, = plt.plot(*pts_scale10[i], 'b.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale10[i]+np.array([x0,y0])), str(i), color='b')\n",
    "\n",
    "    red, = plt.plot(*pts_scale5[i], 'r.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale5[i]+np.array([x0,y0])), str(i), color='r')\n",
    "\n",
    "    grn, = plt.plot(*pts_scale1[i], 'g.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale1[i]+np.array([x0,y0])), str(i), color='g')\n",
    "\n",
    "    \n",
    "plt.axis([0, 1.5, -0.15, 0.2]) # [xmin, xmax, ymin, ymax]\n",
    "plt.legend((blk,blu,red,grn), ('scale20','scale10','scale5','scale1'))\n",
    "\n",
    "plt.savefig('./images/result.png')\n",
    "plt.show()\n",
    "\n",
    "# scale20\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(len(pts_scale10)):\n",
    "    plt.plot(*pts_scale20[i], 'k.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale20[i]+np.array([x0,y0])), str(i), color='k')\n",
    "\n",
    "plt.axis([0, 1.5, -0.15, 0.2]) # [xmin, xmax, ymin, ymax]\n",
    "\n",
    "plt.savefig('./images/result_scale20.png')\n",
    "plt.show()\n",
    "\n",
    "# scale10\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(len(pts_scale10)):\n",
    "    plt.plot(*pts_scale10[i], 'b.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale10[i]+np.array([x0,y0])), str(i), color='b')\n",
    "\n",
    "plt.axis([0, 1.5, -0.15, 0.2]) # [xmin, xmax, ymin, ymax]\n",
    "\n",
    "plt.savefig('./images/result_scale10.png')\n",
    "plt.show()\n",
    "\n",
    "# scale5\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(len(pts_scale10)):\n",
    "    plt.plot(*pts_scale5[i], 'r.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale5[i]+np.array([x0,y0])), str(i), color='r')\n",
    "\n",
    "plt.axis([0, 1.5, -0.15, 0.2]) # [xmin, xmax, ymin, ymax]\n",
    "\n",
    "plt.savefig('./images/result_scale5.png')\n",
    "plt.show()\n",
    "\n",
    "# scale1\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(len(pts_scale10)):\n",
    "    plt.plot(*pts_scale1[i], 'g.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_scale1[i]+np.array([x0,y0])), str(i), color='g')\n",
    "\n",
    "    \n",
    "plt.axis([0, 1.5, -0.15, 0.2]) # [xmin, xmax, ymin, ymax]\n",
    "\n",
    "plt.savefig('./images/result_scale1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do this w.r.t. damping\n",
    "# graphical analysis of stochastic estimation \n",
    "\n",
    "def plot_inverse_hvp_se(model, y, v, data_set, **kwargs):\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # AND plot the process of convergence w.r.t. 2D space\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    # kwargs: hyperparameters for stochastic estimation\n",
    "    recursion_depth = kwargs.pop('recursion_depth', 100) # epoch\n",
    "    scale = kwargs.pop('scale', 1e1) # similar to learning rate\n",
    "    damping = kwargs.pop('damping', 0.0) # paper reference: 0.01\n",
    "    batch_size = kwargs.pop('batch_size', 1)\n",
    "    num_samples = kwargs.pop('num_samples', 1) # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    verbose = kwargs.pop('verbose', False)\n",
    "    graphics = kwargs.pop('graphics', True)\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    pts = [] # graphical points\n",
    "    # pts.append(dic2vec(v))\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "            if verbose:\n",
    "                print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "                print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "            if graphics:\n",
    "                curv = dic2vec(cur_estimate)/scale\n",
    "                if np.isnan(curv).any() or (np.abs(curv)>1e1).any():\n",
    "                    pts.append(1e1*np.ones_like(curv))\n",
    "                else:\n",
    "                    pts.append(curv)\n",
    "\n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    inv_hvp_val = {ks: np.mean([inv_hvps[i][ks] for i in range(num_samples)], axis=0) for ks in inv_hvps[0].keys()}\n",
    "    \n",
    "    return inv_hvp_val, pts\n",
    "\n",
    "# toy example for IHVP: 1D example\n",
    "\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        self.loss = C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "\n",
    "\n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "params[0].value = np.asarray([[1.]])\n",
    "params[1].value = np.asarray([[1./3.]])\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "images = np.asarray([[2.]], dtype=np.float32)\n",
    "labels = np.asarray([[1.]], dtype=np.float32)\n",
    "\n",
    "train_set = SimpleDataset(images,labels)\n",
    "tmp, pts_damp00 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':0.0})\n",
    "print('damp00:', tmp)\n",
    "tmp, pts_damp01 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':0.1})\n",
    "print('damp01:', tmp)\n",
    "tmp, pts_damp05 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':0.5})\n",
    "print('damp05:', tmp)\n",
    "tmp, pts_damp10 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':1.0})\n",
    "print('damp10:', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = -0.01; y0 = 0.01\n",
    "\n",
    "# total\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(len(pts_damp00)):\n",
    "    blk, = plt.plot(*pts_damp00[i], 'k.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_damp00[i]+np.array([x0,y0])), str(i), color='k')\n",
    "\n",
    "    blu, = plt.plot(*pts_damp01[i], 'b.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_damp01[i]+np.array([x0,y0])), str(i), color='b')\n",
    "\n",
    "    red, = plt.plot(*pts_damp05[i], 'r.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_damp05[i]+np.array([x0,y0])), str(i), color='r')\n",
    "\n",
    "    grn, = plt.plot(*pts_damp10[i], 'g.', alpha=min((10+i)/len(pts),1.))\n",
    "    plt.text(*(pts_damp10[i]+np.array([x0,y0])), str(i), color='g')\n",
    "    \n",
    "plt.axis([0, 1.5, -0.15, 0.2]) # [xmin, xmax, ymin, ymax]\n",
    "plt.legend((blk,blu,red,grn), ('damp0.0', 'damp0.1', 'damp0.5', 'damp1.0'))\n",
    "\n",
    "plt.savefig('./images/result_damp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results for scale & damping parameters\n",
    "\n",
    "### Scale\n",
    "\n",
    "![](./images/result_scale.png)\n",
    "![](./images/result_scale20.png)\n",
    "![](./images/result_scale10.png)\n",
    "![](./images/result_scale5.png)\n",
    "![](./images/result_scale1.png)\n",
    "\n",
    "- scale 값이 1.0인 경우를 제외하고는 모두 우리가 원했던 해인 (1.25, -0.083)에 도달했다. \n",
    "- scale이 크면 클 수록 해당 값에 도달하기 위해서 더 많은 step 수가 필요했음을 확인할 수 있다.\n",
    "- scale이 작으면 작을 수록 목표 값에 빨리 도달하나, 더 불안해지는 것을 확인할 수 있었다. 특히 scale이 1일 때에는 3,4 step만에 발산해버린다.\n",
    "- 결론: scale은 (중간에서 발산하는 경우가 아니라면) 최종 해를 변화시키지 않으며, 크면 클 수록 안정적으로 수렴하나 더 많은 step을 요구하게 된다. (즉 learning rate라고 생각하면 됨.)\n",
    "\n",
    "### Damping\n",
    "\n",
    "![](./images/result_damp.png)\n",
    "\n",
    "- 여러 damp값에 대해서 모두 잘 수렴하였다.\n",
    "- 주의할 점은 damp term이 $\\bar{H} = H'+\\gamma I$인데, $H'=\\frac{H}{scale}$이라서 scale과도 연관이 있다.\n",
    "    - 정확하게 설명하자면 damp * scale 만큼의 효과가 있다.\n",
    "    - scale은 learning rate처럼 동작해야하는데, damping term을 추가하게 되면 그렇지 않게 된다. 따라서 최종적으로는 __(원저자의 코드와 달리) damping_new = damping/scale를 사용__해서 구현하기로 했다.\n",
    "- 따라서 0.0, 0.1, 0.5, 1.0을 가지고 damping을 추가하면 사실상 0.0, 1.0, 5.0, 10.0의 damping term이 들어간 효과가 나게 된다.\n",
    "- 이를 가지고 numerical하게 $(H+\\gamma I)^{-1} v$ 값을 계산하면, (1.25, -0.083), (0.5036, 0.0365), (0.1560, 0.0609), (0.0858, 0.0492) 값이 나오게 된다.\n",
    "- 모든 결과 예측한 수치값에 잘 수렴한 것을 확인할 수 있다.\n",
    "- 하지만 damp term을 추가하게 되면, 이 값이 크면 클 수록 inverse hessian vector product 값도 바뀔 가능성이 커진다는 것을 유의해야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stochastic estimation\n",
    "def get_inverse_hvp_se(model, y, v, data_set, **kwargs):\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    # kwargs: hyperparameters for stochastic estimation\n",
    "    recursion_depth = kwargs.pop('recursion_depth', 50) # epoch\n",
    "    scale = kwargs.pop('scale', 1e1) # similar to learning rate\n",
    "    damping = kwargs.pop('damping', 0.0) # paper reference: 0.01\n",
    "    batch_size = kwargs.pop('batch_size', 1)\n",
    "    num_samples = kwargs.pop('num_samples', 1) # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    verbose = kwargs.pop('verbose', False)\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping/scale)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "            if verbose:\n",
    "                print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "                print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "        \n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    inv_hvp_val = {ks: np.mean([inv_hvps[i][ks] for i in range(num_samples)], axis=0) for ks in inv_hvps[0].keys()}\n",
    "    \n",
    "    return inv_hvp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = \n",
      " [[ 0.0370382]] \n",
      "w2 = \n",
      " [[-0.03171763]] \n",
      "loss = \n",
      " [ 1.00470448]\n",
      "w1 = \n",
      " [[ 1.]] \n",
      "w2 = \n",
      " [[ 0.33333334]] \n",
      "loss = \n",
      " [ 0.1111111]\n",
      "hvp {Parameter('W', [], [1 x 1]): array([[ 2.22302079]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 9.33413506]], dtype=float32)}\n",
      "damp00: {Parameter('W', [], [1 x 1]): array([[ 1.24517536]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.08125092]], dtype=float32)}\n",
      "damp01: {Parameter('W', [], [1 x 1]): array([[ 1.08393502]], dtype=float32), Parameter('W', [], [1 x 1]): array([[-0.05433164]], dtype=float32)}\n",
      "damp05: {Parameter('W', [], [1 x 1]): array([[ 0.71470672]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 0.00550994]], dtype=float32)}\n",
      "damp10: {Parameter('W', [], [1 x 1]): array([[ 0.50368214]], dtype=float32), Parameter('W', [], [1 x 1]): array([[ 0.03640944]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# do this w.r.t. damping\n",
    "# graphical analysis of stochastic estimation \n",
    "\n",
    "def plot_inverse_hvp_se(model, y, v, data_set, **kwargs):\n",
    "    # Calculate inverse hessian vector product over the training set\n",
    "    # AND plot the process of convergence w.r.t. 2D space\n",
    "    # model: neural network model (e.g. model)\n",
    "    # y: scalar function output of the neural network (e.g. model.loss)\n",
    "    # v: vector to be producted by inverse hessian (i.e.H^-1 v) (e.g. v_test)\n",
    "    # data_set: training set to be summed in Hessian\n",
    "    # kwargs: hyperparameters for stochastic estimation\n",
    "    recursion_depth = kwargs.pop('recursion_depth', 100) # epoch\n",
    "    scale = kwargs.pop('scale', 1e1) # similar to learning rate\n",
    "    damping = kwargs.pop('damping', 0.0) # paper reference: 0.01\n",
    "    batch_size = kwargs.pop('batch_size', 1)\n",
    "    num_samples = kwargs.pop('num_samples', 1) # the number of samples(:stochatic estimation of IF) to be averaged\n",
    "    verbose = kwargs.pop('verbose', False)\n",
    "    graphics = kwargs.pop('graphics', True)\n",
    "    \n",
    "    dataloader = DataLoader(data_set, batch_size, shuffle=True, num_workers=6)\n",
    "    \n",
    "    inv_hvps = []\n",
    "    \n",
    "    pts = [] # graphical points\n",
    "    # pts.append(dic2vec(v))\n",
    "    \n",
    "    params = y.parameters\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # obtain num_samples inverse hvps\n",
    "        cur_estimate = v\n",
    "        \n",
    "        for depth in range(recursion_depth):\n",
    "            # epoch-scale recursion depth\n",
    "            t1 = time.time()\n",
    "            for img, lb in dataloader:\n",
    "                img = img.numpy(); lb = lb.numpy()\n",
    "                x_feed = {model.X: img, model.y:lb}\n",
    "                hvp = HVP(y,x_feed,cur_estimate)\n",
    "                # cur_estimate = v + (1-damping)*cur_estimate + 1/scale*(hvp/batch_size)\n",
    "                cur_estimate = {ks: v[ks] + (1-damping/scale)*cur_estimate[ks] - (1/scale)*hvp[ks]/batch_size for ks in cur_estimate.keys()}\n",
    "            if verbose:\n",
    "                print('#w: \\n', list(map(lambda x: x.value, params)), '\\n#hvp: \\n', hvp, '\\n#ihvp: \\n', cur_estimate)\n",
    "                print(\"Recursion depth: {}, norm: {}, time: {} \\n\".format(depth, np.sqrt(grad_inner_product(cur_estimate,cur_estimate)),time.time()-t1))\n",
    "            if graphics:\n",
    "                curv = dic2vec(cur_estimate)/scale\n",
    "                if np.isnan(curv).any() or (np.abs(curv)>1e1).any():\n",
    "                    pts.append(1e1*np.ones_like(curv))\n",
    "                else:\n",
    "                    pts.append(curv)\n",
    "\n",
    "        inv_hvp = {ks: (1/scale)*cur_estimate[ks] for ks in cur_estimate.keys()}\n",
    "        inv_hvps.append(inv_hvp)\n",
    "    \n",
    "    inv_hvp_val = {ks: np.mean([inv_hvps[i][ks] for i in range(num_samples)], axis=0) for ks in inv_hvps[0].keys()}\n",
    "    \n",
    "    return inv_hvp_val, pts\n",
    "\n",
    "# toy example for IHVP: 1D example\n",
    "\n",
    "class SimpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.X = C.input_variable(shape=(1,))\n",
    "        self.h = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.X)\n",
    "        self.pred = C.layers.Dense(1, activation=None, init=C.uniform(1), bias=False)(self.h)\n",
    "        self.y = C.input_variable(shape=(1,))\n",
    "        self.loss = C.squared_error(self.pred, self.y)\n",
    "        \n",
    "class SimpleDataset(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._images, self._labels = images, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self._images[index]\n",
    "        y = self._labels[index]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._images)\n",
    "\n",
    "\n",
    "net = SimpleNet()\n",
    "\n",
    "params = net.pred.parameters\n",
    "\n",
    "x_feed = {net.X:np.array([[2.]],dtype=np.float32), net.y:np.array([[1.]],dtype=np.float32)}\n",
    "v_feed = {p: np.ones_like(p.value) for p in params}\n",
    "\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "params[0].value = np.asarray([[1.]])\n",
    "params[1].value = np.asarray([[1./3.]])\n",
    "print('w1 = \\n', params[0].value, '\\nw2 = \\n', params[1].value, '\\nloss = \\n', net.loss.eval(x_feed))\n",
    "\n",
    "print('hvp', HVP(net.loss, x_feed, v_feed))\n",
    "\n",
    "#images = np.asarray([[2.],[2.]], dtype=np.float32)\n",
    "#labels = np.asarray([[1.],[1.]], dtype=np.float32)\n",
    "images = np.asarray([[2.]], dtype=np.float32)\n",
    "labels = np.asarray([[1.]], dtype=np.float32)\n",
    "\n",
    "train_set = SimpleDataset(images,labels)\n",
    "tmp, pts_damp00 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':0.0})\n",
    "print('damp00:', tmp)\n",
    "tmp, pts_damp01 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':0.1})\n",
    "print('damp01:', tmp)\n",
    "tmp, pts_damp05 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':0.5})\n",
    "print('damp05:', tmp)\n",
    "tmp, pts_damp10 = plot_inverse_hvp_se(net, net.loss, v_feed, train_set, **{'damping':1.0})\n",
    "print('damp10:', tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- cntk의 구현 상 이유로 automatic differentiation 대신 numerical differentiation을 사용해서 HVP를 구현함.\n",
    "- Conjugate gradient\n",
    "    - scipy를 사용해서 구현했고, 검증을 함.\n",
    "- Stocastic estimation\n",
    "    - 논문에는 없지만 원저자 코드에 있는 term, minibatch, scale을 추가함.\n",
    "        - scale이 learning rate와 비슷한 개념임을 예측하고 확인함.\n",
    "    - 원저자와 달리 damping을 scale로 나눠서 사용해, scale을 바꾸더라도 최종 output이 변화가 없게 함.\n",
    "    - locally convex한 상황에서 scale을 잘 정한다면 원하던 값에 수렴한다는 것을 확인함.\n",
    "    - 반대로 말하자면 hyperparameter를 잘 잡아주지 못하면 원하던 값에 수렴시킬 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cntk]",
   "language": "python",
   "name": "conda-env-cntk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
